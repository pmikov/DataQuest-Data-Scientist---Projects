{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Dataset\n",
    "\n",
    "In this mission, you'll be working with a csv file containing index prices. Each row in the file contains a daily record of the price of the S&P500 Index from 1950 to 2015. The dataset is stored in sphist.csv.\n",
    "\n",
    "The columns of the dataset are:\n",
    "\n",
    "- Date -- The date of the record.\n",
    "- Open -- The opening price of the day (when trading starts).\n",
    "- High -- The highest trade price during the day.\n",
    "- Low -- The lowest trade price during the day.\n",
    "- Close -- The closing price for the day (when trading is finished).\n",
    "- Volume -- The number of shares traded.\n",
    "- Adj Close -- The daily closing price, adjusted retroactively to include any corporate actions. Read more here.\n",
    "\n",
    "You'll be using this dataset to develop a predictive model. You'll train the model with data from 1950-2012, and try to make predictions from 2013-2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading in the data\n",
    "\n",
    "You'll need to read the data into Python, do some processing to set the right column types, and then sort the dataframe. You can do this in the predict.py script.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Here are the steps you'll need to take, at a high level:\n",
    "\n",
    "\n",
    "Read the data into a Pandas DataFrame. You can use the read_csv Pandas function for this.\n",
    "\n",
    "Convert the Date column to a Pandas date type. This will allow you to do date comparisons with the column.\n",
    "- You can perform this conversion with the to_datetime function in Pandas.\n",
    "- Once you convert the column, you can perform comparisons with df[\"Date\"] > datetime(year=2015, month=4, day=1). This will generate a Boolean series that tells you if each item in the Date column is after 2015-04-01. You'll have to import the datetime module from the datetime library first with from datetime import datetime.\n",
    "\n",
    "Sort the dataframe on the Date column. It's currently in descending order, but we'll want it to be in ascending order for some of the next steps. You can use the DataFrame.sort_values() method on data frames for this.\n",
    "\n",
    "Make sure to run the predict.py script using python predict.py as you work through the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950-01-03</td>\n",
       "      <td>16.660000</td>\n",
       "      <td>16.660000</td>\n",
       "      <td>16.660000</td>\n",
       "      <td>16.660000</td>\n",
       "      <td>1.260000e+06</td>\n",
       "      <td>16.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950-01-04</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>1.890000e+06</td>\n",
       "      <td>16.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950-01-05</td>\n",
       "      <td>16.930000</td>\n",
       "      <td>16.930000</td>\n",
       "      <td>16.930000</td>\n",
       "      <td>16.930000</td>\n",
       "      <td>2.550000e+06</td>\n",
       "      <td>16.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1950-01-06</td>\n",
       "      <td>16.980000</td>\n",
       "      <td>16.980000</td>\n",
       "      <td>16.980000</td>\n",
       "      <td>16.980000</td>\n",
       "      <td>2.010000e+06</td>\n",
       "      <td>16.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1950-01-09</td>\n",
       "      <td>17.080000</td>\n",
       "      <td>17.080000</td>\n",
       "      <td>17.080000</td>\n",
       "      <td>17.080000</td>\n",
       "      <td>2.520000e+06</td>\n",
       "      <td>17.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16585</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>2082.929932</td>\n",
       "      <td>2103.370117</td>\n",
       "      <td>2082.929932</td>\n",
       "      <td>2102.629883</td>\n",
       "      <td>3.712120e+09</td>\n",
       "      <td>2102.629883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16586</th>\n",
       "      <td>2015-12-02</td>\n",
       "      <td>2101.709961</td>\n",
       "      <td>2104.270020</td>\n",
       "      <td>2077.110107</td>\n",
       "      <td>2079.510010</td>\n",
       "      <td>3.950640e+09</td>\n",
       "      <td>2079.510010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16587</th>\n",
       "      <td>2015-12-03</td>\n",
       "      <td>2080.709961</td>\n",
       "      <td>2085.000000</td>\n",
       "      <td>2042.349976</td>\n",
       "      <td>2049.620117</td>\n",
       "      <td>4.306490e+09</td>\n",
       "      <td>2049.620117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16588</th>\n",
       "      <td>2015-12-04</td>\n",
       "      <td>2051.239990</td>\n",
       "      <td>2093.840088</td>\n",
       "      <td>2051.239990</td>\n",
       "      <td>2091.689941</td>\n",
       "      <td>4.214910e+09</td>\n",
       "      <td>2091.689941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16589</th>\n",
       "      <td>2015-12-07</td>\n",
       "      <td>2090.419922</td>\n",
       "      <td>2090.419922</td>\n",
       "      <td>2066.780029</td>\n",
       "      <td>2077.070068</td>\n",
       "      <td>4.043820e+09</td>\n",
       "      <td>2077.070068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16590 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date         Open         High          Low        Close  \\\n",
       "0     1950-01-03    16.660000    16.660000    16.660000    16.660000   \n",
       "1     1950-01-04    16.850000    16.850000    16.850000    16.850000   \n",
       "2     1950-01-05    16.930000    16.930000    16.930000    16.930000   \n",
       "3     1950-01-06    16.980000    16.980000    16.980000    16.980000   \n",
       "4     1950-01-09    17.080000    17.080000    17.080000    17.080000   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "16585 2015-12-01  2082.929932  2103.370117  2082.929932  2102.629883   \n",
       "16586 2015-12-02  2101.709961  2104.270020  2077.110107  2079.510010   \n",
       "16587 2015-12-03  2080.709961  2085.000000  2042.349976  2049.620117   \n",
       "16588 2015-12-04  2051.239990  2093.840088  2051.239990  2091.689941   \n",
       "16589 2015-12-07  2090.419922  2090.419922  2066.780029  2077.070068   \n",
       "\n",
       "             Volume    Adj Close  \n",
       "0      1.260000e+06    16.660000  \n",
       "1      1.890000e+06    16.850000  \n",
       "2      2.550000e+06    16.930000  \n",
       "3      2.010000e+06    16.980000  \n",
       "4      2.520000e+06    17.080000  \n",
       "...             ...          ...  \n",
       "16585  3.712120e+09  2102.629883  \n",
       "16586  3.950640e+09  2079.510010  \n",
       "16587  4.306490e+09  2049.620117  \n",
       "16588  4.214910e+09  2091.689941  \n",
       "16589  4.043820e+09  2077.070068  \n",
       "\n",
       "[16590 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sphist.csv')\n",
    "df['Date'] = pd.to_datetime(df.Date)\n",
    "df.sort_values(by=\"Date\", ascending=True, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating indicators\n",
    "\n",
    "Datasets taken from the stock market need to be handled differently than datasets from other sectors when it comes time to make predictions. In a normal machine learning exercise, we treat each row as independent. Stock market data is sequential, and each observation comes a day after the previous observation. Thus, the observations are not all independent, and you can't treat them as such.\n",
    "\n",
    "This means you have to be extra careful to not inject \"future\" knowledge into past rows when you do training and prediction. Injecting future knowledge will make our model look good when you're training and testing it, but will make it fail in the real world. This is how many algorithmic traders lose money.\n",
    "\n",
    "The time series nature of the data means that can generate indicators to make our model more accurate. For instance, you can create a new column that contains the average price of the last 10 trades for each row. This will incorporate information from multiple prior rows into one, and will make predictions much more accurate.\n",
    "\n",
    "When you do this, you have to be careful not to use the current row in the values you average. You want to teach the model how to predict the current price from historical prices. If you include the current price in the prices you average, it will be equivalent to handing the answers to the model upfront, and will make it impossible to use in the \"real world\", where you don't know the price upfront.\n",
    "\n",
    "Here are some indicators that are interesting to generate for each row:\n",
    "\n",
    "- The average price from the past 5 days.\n",
    "- The average price for the past 30 days.\n",
    "- The average price for the past 365 days.\n",
    "- The ratio between the average price for the past 5 days, and the average price for the past 365 days.\n",
    "- The standard deviation of the price over the past 5 days.\n",
    "- The standard deviation of the price over the past 365 days.\n",
    "- The ratio between the standard deviation for the past 5 days, and the standard deviation for the past 365 days.\n",
    "\n",
    "\"Days\" means \"trading days\" -- so if you're computing the average of the past 5 days, it should be the 5 most recent dates before the current one. Assume that \"price\" means the Close column. Always be careful not to include the current price in these indicators! You're predicting the next day price, so our indicators are designed to predict the current price from the previous prices.\n",
    "\n",
    "Some of these indicators require a year of historical data to compute. Our first day of data falls on 1950-01-03, so the first day you can start computing indicators on is 1951-01-03.\n",
    "\n",
    "To compute indicators, you'll need to loop through each day from 1951-01-03 to 2015-12-07 (the last day you have prices for). For instance, if we were computing the average price from the past 5 days, we'd start at 1951-01-03, get the prices for each day from 1950-12-26 to 1951-01-02, and find the average. The reason why we start on the 26th, and take more than 5 calendar days into account is because the stock market is shutdown on certain holidays. Since we're looking at the past 5 trading days, we need to look at more than 5 calendar days to find them. \n",
    "\n",
    "We'd keep repeating this process to compute all of the averages. Note how when we compute the average of the past 5 days for 1951-01-04, we don't include 1951-01-04 in that average. It's critical not to do this, or our model won't work in the \"real world\".\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Pick 3 indicators to compute, and generate a different column for each one.\n",
    "\n",
    "There are a few different ways to do this:\n",
    "\n",
    "- You can use a for loop along with the [iterrows method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iterrows.html) to loop over the rows in the DataFrame and compute the indicators. This is the recommended way, as it's a bit simpler to understand what's happening. Since you'll be looping over all of the rows, for any date that comes before there is enough historical data to compute an indicator, just fill in 0.\n",
    "- Pandas has some [time series tools](https://pandas.pydata.org/pandas-docs/stable/user_guide/computation.html) that can help, including [the rolling function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rolling.html), which will do most of the hard computation for you. Set the window equal to the number of trading days in the past you want to use to compute the indicators. This will add in NaN values for any row where there aren't enough historical trading days to do the computation. Note: There is a giant caveat here, which is that the rolling mean will use the current day's price. You'll need to reindex the resulting series to shift all the values \"forward\" one day. For example, the rolling mean calculated for 1950-01-03 will need to be assigned to 1950-01-04, and so on. You can use the [shift method](https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.shift.html) on Dataframes to do this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"avg_5\"] = df[\"Close\"].rolling(5).mean().shift(1)\n",
    "df[\"avg_30\"] = df[\"Close\"].rolling(30).mean().shift(1)\n",
    "df[\"avg_365\"] = df[\"Close\"].rolling(365).mean().shift(1)\n",
    "\n",
    "df[\"std_5\"] = df[\"Close\"].rolling(5).std().shift(1)\n",
    "df[\"std_365\"] = df[\"Close\"].rolling(365).std().shift(1)\n",
    "\n",
    "df[\"avg_5/avg_365\"] = df[\"avg_5\"]/df[\"avg_365\"]\n",
    "df[\"std_5/std_365\"] = df[\"std_5\"]/df[\"std_365\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Splitting up the data\n",
    "\n",
    "Since you're computing indicators that use historical data, there are some rows where there isn't enough historical data to generate them. Some of the indicators use 365 days of historical data, and the dataset starts on 1950-01-03. Thus, any rows that fall before 1951-01-03 don't have enough historical data to compute all the indicators. You'll need to remove these rows before you split the data.\n",
    "\n",
    "If you have a Dataframe df, you can select any rows with the Date column greater than 1951-01-02 using df[df[\"Date\"] > datetime(year=1951, month=1, day=2)].\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Remove any rows from the DataFrame that fall before 1951-01-03.\n",
    "- Use the dropna method to remove any rows with NaN values. Pass in the axis=0 argument to drop rows.\n",
    "- Generate two new dataframes to use in making our algorithm. train should contain any rows in the data with a date less than 2013-01-01. test should contain any rows with a date greater than or equal to 2013-01-01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)\n",
    "df_train = df[df[\"Date\"] < datetime(year=2013, month=1, day=1)]\n",
    "df_test = df[df[\"Date\"] >= datetime(year=2013, month=1, day=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Making predictions\n",
    "\n",
    "Now, you can define an error metric, train a model using the train data, and make predictions on the test data.\n",
    "\n",
    "It's recommended to use Mean Absolute Error, also called MAE, as an error metric, because it will show you how \"close\" you were to the price in intuitive terms. Mean Squared Error, or MSE, is an alternative that is more commonly used, but makes it harder to intuitively tell how far off you are from the true price because it squares the error.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Pick an error metric.\n",
    "- Initialize an instance of the LinearRegression class.\n",
    "- Train a linear regression model, using the train Dataframe. Leave out all of the original columns (Close, High, Low, Open, Volume, Adj Close, Date) when training your model. These all contain knowledge of the future that you don't want to feed the model. Use the Close column as the target.\n",
    "- Make predictions for the Close column of the test data, using the same columns for training as you did with train.\n",
    "- Compute the error between the predictions and the Close column of test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  16.145140609743393\n",
      "MSE:  492.9230344450359\n",
      "0.9995223668123336\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "features = [\"avg_5\", \"avg_30\", \"avg_365\", \"std_5\", \"std_365\", \"avg_5/avg_365\", \"std_5/std_365\"]\n",
    "#model.fit(train[features], train[\"Close\"])\n",
    "#predictions = model.predict(test[features])\n",
    "x = df_train[features]\n",
    "x_test = df_test[features]\n",
    "y = df_train.Close\n",
    "y_test = df_test.Close\n",
    "\n",
    "model.fit(x, y)\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Calculate error metrics\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MAE: \", mae)\n",
    "print(\"MSE: \", mse)\n",
    "print(model.score(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date       Open       High        Low      Close     Volume  \\\n",
      "0  1950-01-03  16.660000  16.660000  16.660000  16.660000  1260000.0   \n",
      "1  1950-01-04  16.850000  16.850000  16.850000  16.850000  1890000.0   \n",
      "2  1950-01-05  16.930000  16.930000  16.930000  16.930000  2550000.0   \n",
      "3  1950-01-06  16.980000  16.980000  16.980000  16.980000  2010000.0   \n",
      "4  1950-01-09  17.080000  17.080000  17.080000  17.080000  2520000.0   \n",
      "5  1950-01-10  17.030001  17.030001  17.030001  17.030001  2160000.0   \n",
      "6  1950-01-11  17.090000  17.090000  17.090000  17.090000  2630000.0   \n",
      "7  1950-01-12  16.760000  16.760000  16.760000  16.760000  2970000.0   \n",
      "8  1950-01-13  16.670000  16.670000  16.670000  16.670000  3330000.0   \n",
      "9  1950-01-16  16.719999  16.719999  16.719999  16.719999  1460000.0   \n",
      "10 1950-01-17  16.860001  16.860001  16.860001  16.860001  1790000.0   \n",
      "11 1950-01-18  16.850000  16.850000  16.850000  16.850000  1570000.0   \n",
      "12 1950-01-19  16.870001  16.870001  16.870001  16.870001  1170000.0   \n",
      "13 1950-01-20  16.900000  16.900000  16.900000  16.900000  1440000.0   \n",
      "14 1950-01-23  16.920000  16.920000  16.920000  16.920000  1340000.0   \n",
      "\n",
      "    Adj Close  \n",
      "0   16.660000  \n",
      "1   16.850000  \n",
      "2   16.930000  \n",
      "3   16.980000  \n",
      "4   17.080000  \n",
      "5   17.030001  \n",
      "6   17.090000  \n",
      "7   16.760000  \n",
      "8   16.670000  \n",
      "9   16.719999  \n",
      "10  16.860001  \n",
      "11  16.850000  \n",
      "12  16.870001  \n",
      "13  16.900000  \n",
      "14  16.920000  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([249], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(df[df[\"Date\"] == datetime(year=1951, month=1, day=2)].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Improving error\n",
    "\n",
    "Congratulations! You can now predict the S&P500 (with some error). You can improve the error of this model significantly, though. Think about some indicators that might be helpful to compute.\n",
    "\n",
    "Here are some ideas that might be helpful:\n",
    "\n",
    "- The average volume over the past five days.\n",
    "- The average volume over the past year.\n",
    "- The ratio between the average volume for the past five days, and the average volume for the past year.\n",
    "- The standard deviation of the average volume over the past five days.\n",
    "- The standard deviation of the average volume over the past year.\n",
    "- The ratio between the standard deviation of the average volume for the past five days, and the standard deviation of the average volume for the past year.\n",
    "- The year component of the date.\n",
    "- The ratio between the lowest price in the past year and the current price.\n",
    "- The ratio between the highest price in the past year and the current price.\n",
    "- The month component of the date.\n",
    "- The day of week.\n",
    "- The day component of the date.\n",
    "- The number of holidays in the prior month.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Add 2 additional indicators to your dataframe, and see if the error is reduced. You'll need to insert these indicators at the same point where you insert the others, before you clean out rows with NaN values and split the dataframe into train and `test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next steps\n",
    "\n",
    "There's a lot of improvement still to be made on the indicator side, and we urge you to think of better indicators that you could use for prediction. We can also make significant structural improvements to the algorithm, and pull in data from other sources.\n",
    "\n",
    "- Accuracy would improve greatly by making predictions only one day ahead. For example, train a model using data from 1951-01-03 to 2013-01-02, make predictions for 2013-01-03, and then train another model using data from 1951-01-03 to 2013-01-03, make predictions for 2013-01-04, and so on. This more closely simulates what you'd do if you were trading using the algorithm.\n",
    "\n",
    "- You can also improve the algorithm used significantly. Try other techniques, like a random forest, and see if they perform better.\n",
    "\n",
    "- You can also incorporate outside data, such as the weather in New York City (where most trading happens) the day before, and the amount of Twitter activity around certain stocks.\n",
    "\n",
    "- You can also make the system real-time by writing an automated script to download the latest data when the market closes, and make predictions for the next day.\n",
    "\n",
    "- Finally, you can make the system \"higher-resolution\". You're currently making daily predictions, but you could make hourly, minute-by-minute, or second by second predictions. This will require obtaining more data, though. You could also make predictions for individual stocks instead of the S&P500."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
